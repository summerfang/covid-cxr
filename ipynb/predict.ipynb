{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def remove_text(img):\n",
    "    '''\n",
    "    Attempts to remove bright textual artifacts from X-ray images. For example, many images indicate the right side of\n",
    "    the body with a white 'R'. Works only for very bright text.\n",
    "    :param img: Numpy array of image\n",
    "    :return: Array of image with (ideally) any characters removed and inpainted\n",
    "    '''\n",
    "    mask = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY)[1][:, :, 0].astype(np.uint8)\n",
    "    img = img.astype(np.uint8)\n",
    "    result = cv2.inpaint(img, mask, 10, cv2.INPAINT_NS).astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "def visualize_explanation(orig_img, explanation, img_filename, label, probs, class_names, label_to_see='top', dir_path=None):\n",
    "    '''\n",
    "    Visualize an explanation for the prediction of a single X-ray image.\n",
    "    :param orig_img: Original X-Ray image\n",
    "    :param explanation: ImageExplanation object\n",
    "    :param img_filename: Filename of the image explained\n",
    "    :param label: Ground truth class of the example\n",
    "    :param probs: Prediction probabilities\n",
    "    :param class_names: Ordered list of class names\n",
    "    :param label_to_see: Label to visualize in explanation\n",
    "    :param dir_path: Path to directory where to save the generated image\n",
    "    :return: Path to saved image\n",
    "    '''\n",
    "\n",
    "    # Plot original image on the left\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(orig_img)\n",
    "\n",
    "    # Plot the image and its explanation on the right\n",
    "    if label_to_see == 'top':\n",
    "        label_to_see = explanation.top_labels[0]\n",
    "    explanation.image = orig_img\n",
    "    temp, mask = explanation.get_image_and_mask(label_to_see, positive_only=False, num_features=10,\n",
    "                                                hide_rest=False)\n",
    "    ax[1].imshow(mark_boundaries(temp, mask))\n",
    "\n",
    "    # Display some information about the example\n",
    "    pred_class = np.argmax(probs)\n",
    "    fig.text(0.02, 0.8, \"Prediction probabilities: \" + str(['{:.2f}'.format(probs[i]) for i in range(len(probs))]),\n",
    "             fontsize=10)\n",
    "    fig.text(0.02, 0.82, \"Predicted Class: \" + str(pred_class) + ' (' + class_names[pred_class] + ')', fontsize=10)\n",
    "    if label is not None:\n",
    "        fig.text(0.02, 0.84, \"Ground Truth Class: \" + str(label) + ' (' + class_names[label] + ')', fontsize=10)\n",
    "    fig.suptitle(\"LIME Explanation for image \" + img_filename, fontsize=13)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the image\n",
    "    filename = None\n",
    "    if dir_path is not None:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        filename = dir_path + img_filename.split('/')[-1] + '_exp_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.png'\n",
    "        plt.savefig(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import dill\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "#from src.data.preprocess import remove_text\n",
    "from src.visualization.visualize import visualize_explanation\n",
    "\n",
    "\n",
    "def predict_instance(x, model):\n",
    "    '''\n",
    "    Runs model prediction on 1 or more input images.\n",
    "    :param x: Image(s) to predict\n",
    "    :param model: A Keras model\n",
    "    :return: A numpy array comprising a list of class probabilities for each prediction\n",
    "    '''\n",
    "    y = model.predict(x)  # Run prediction on the perturbations\n",
    "    if y.shape[1] == 1:\n",
    "        probs = np.concatenate([1.0 - y, y], axis=1)  # Compute class probabilities from the output of the model\n",
    "    else:\n",
    "        probs = y\n",
    "    return probs\n",
    "\n",
    "\n",
    "def predict_and_explain(x, model, exp, num_features, num_samples):\n",
    "    '''\n",
    "    Use the model to predict a single example and apply LIME to generate an explanation.\n",
    "    :param x: Preprocessed image to predict\n",
    "    :param model: The trained neural network model\n",
    "    :param exp: A LimeImageExplainer object\n",
    "    :param num_features: # of features to use in explanation\n",
    "    :param num_samples: # of times to perturb the example to be explained\n",
    "    :return: The LIME explainer for the instance\n",
    "    '''\n",
    "\n",
    "    def predict(x):\n",
    "        '''\n",
    "        Helper function for LIME explainer. Runs model prediction on perturbations of the example.\n",
    "        :param x: List of perturbed examples from an example\n",
    "        :return: A numpy array constituting a list of class probabilities for each predicted perturbation\n",
    "        '''\n",
    "        probs = predict_instance(x, model)\n",
    "        return probs\n",
    "\n",
    "    # Algorithm for superpixel segmentation. Parameters set to limit size of superpixels and promote border smoothness\n",
    "    segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=2.25, max_dist=50, ratio=0.1, sigma=0.15)\n",
    "\n",
    "    # Generate explanation for the example\n",
    "    explanation = exp.explain_instance(x, predict, num_features=num_features, num_samples=num_samples, segmentation_fn=segmentation_fn)\n",
    "    probs = predict_instance(np.expand_dims(x, axis=0), model)\n",
    "    return explanation, probs\n",
    "\n",
    "\n",
    "def predict_and_explain_set(raw_img_dir=None, preds_dir=None, save_results=True, give_explanations=True):\n",
    "    '''\n",
    "    Preprocess a raw dataset. Then get model predictions and corresponding explanations.\n",
    "    :param raw_img_dir: Directory in which to look for raw images\n",
    "    :param preds_dir: Path at which to save results of this prediction\n",
    "    :param save_results: Flag specifying whether to save the prediction results to disk\n",
    "    :param give_explanations: Flag specifying whether to provide LIME explanations with predictions spreadsheet\n",
    "    :return: Dataframe of prediction results, optionally including explanations.\n",
    "    '''\n",
    "\n",
    "    # Load project config data\n",
    "    cfg = yaml.full_load(open(os.getcwd() + \"/config.yml\", 'r'))\n",
    "    cur_date = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "    # Restore the model, LIME explainer, and model class indices from their respective serializations\n",
    "    model = load_model(cfg['PATHS']['MODEL_TO_LOAD'], compile=False)\n",
    "    explainer = dill.load(open(cfg['PATHS']['LIME_EXPLAINER'], 'rb'))\n",
    "    class_indices = dill.load(open(cfg['PATHS']['OUTPUT_CLASS_INDICES'], 'rb'))\n",
    "\n",
    "    # Load LIME and prediction constants from config\n",
    "    NUM_SAMPLES = cfg['LIME']['NUM_SAMPLES']\n",
    "    NUM_FEATURES = cfg['LIME']['NUM_FEATURES']\n",
    "    CLASS_NAMES = cfg['DATA']['CLASSES']\n",
    "\n",
    "    # Define column names of the DataFrame representing the prediction results\n",
    "    col_names = ['Image Filename', 'Predicted Class']\n",
    "    for c in cfg['DATA']['CLASSES']:\n",
    "        col_names.append('p(' + c + ')')\n",
    "\n",
    "    # Add columns for client explanation\n",
    "    if give_explanations:\n",
    "        col_names.append('Explanation Filename')\n",
    "\n",
    "    # Set raw image directory based on project config, if not specified\n",
    "    if raw_img_dir is None:\n",
    "        raw_img_dir = cfg['PATHS']['BATCH_PRED_IMGS']\n",
    "\n",
    "    # If no path is specified, create new directory for predictions\n",
    "    if preds_dir is None:\n",
    "        preds_dir = cfg['PATHS']['BATCH_PREDS'] + '/' + cur_date + '/'\n",
    "        if save_results and not os.path.exists(cfg['PATHS']['BATCH_PREDS'] + '/' + cur_date):\n",
    "            os.mkdir(preds_dir)\n",
    "\n",
    "    # Create DataFrame for raw image file names\n",
    "    raw_img_df = pd.DataFrame({'filename': os.listdir(raw_img_dir)})\n",
    "    raw_img_df = raw_img_df[raw_img_df['filename'].str.contains('jpg|png|jpeg', na=False)]   # Enforce image files\n",
    "\n",
    "    # Create generator for the image files\n",
    "    img_gen = ImageDataGenerator(preprocessing_function=remove_text, samplewise_std_normalization=True,\n",
    "                                 samplewise_center=True)\n",
    "    img_iter = img_gen.flow_from_dataframe(dataframe=raw_img_df, directory=raw_img_dir, x_col=\"filename\",\n",
    "                                           target_size=cfg['DATA']['IMG_DIM'], batch_size=1, class_mode=None,\n",
    "                                           shuffle=False)\n",
    "\n",
    "    # Predict (and optionally explain) all images in the specified directory\n",
    "    rows = []\n",
    "    print('Predicting and explaining examples.')\n",
    "\n",
    "    for filename in raw_img_df['filename'].tolist():\n",
    "\n",
    "        # Get preprocessed image and make a prediction.\n",
    "        try:\n",
    "            x = img_iter.next()\n",
    "        except StopIteration:\n",
    "            break\n",
    "        y = np.squeeze(predict_instance(x, model))\n",
    "\n",
    "        # Rearrange prediction probability vector to reflect original ordering of classes in project config\n",
    "        p = [y[CLASS_NAMES.index(c)] for c in class_indices]\n",
    "        predicted_class = CLASS_NAMES[np.argmax(p)]\n",
    "        row = [filename, predicted_class]\n",
    "        row.extend(list(p))\n",
    "\n",
    "        # Explain this prediction\n",
    "        if give_explanations:\n",
    "            explanation, _ = predict_and_explain(np.squeeze(x, axis=0), model, explainer, NUM_FEATURES, NUM_SAMPLES)\n",
    "            if cfg['LIME']['COVID_ONLY'] == True:\n",
    "                label_to_see = class_indices['COVID-19']\n",
    "            else:\n",
    "                label_to_see = 'top'\n",
    "\n",
    "            # Load and resize the corresponding original image (no preprocessing)\n",
    "            orig_img = cv2.imread(raw_img_dir + filename)\n",
    "            orig_img = cv2.resize(orig_img, tuple(cfg['DATA']['IMG_DIM']), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            # Generate visual for explanation\n",
    "            exp_filename = visualize_explanation(orig_img, explanation, filename, None, p, CLASS_NAMES,\n",
    "                                                 label_to_see=label_to_see, dir_path=preds_dir)\n",
    "            row.append(exp_filename.split('/')[-1])\n",
    "        rows.append(row)\n",
    "\n",
    "    # Convert results to a Pandas DataFrame and save\n",
    "    results_df = pd.DataFrame(rows, columns=col_names)\n",
    "    if save_results:\n",
    "        results_path = preds_dir + 'predictions.csv'\n",
    "        results_df.to_csv(results_path, columns=col_names, index_label=False, index=False)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_and_explain_set(preds_dir=None, save_results=True, give_explanations=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
