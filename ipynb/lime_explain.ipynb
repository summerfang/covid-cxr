{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import datetime\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "def visualize_explanation(orig_img, explanation, img_filename, label, probs, class_names, label_to_see='top', dir_path=None):\n",
    "    '''\n",
    "    Visualize an explanation for the prediction of a single X-ray image.\n",
    "    :param orig_img: Original X-Ray image\n",
    "    :param explanation: ImageExplanation object\n",
    "    :param img_filename: Filename of the image explained\n",
    "    :param label: Ground truth class of the example\n",
    "    :param probs: Prediction probabilities\n",
    "    :param class_names: Ordered list of class names\n",
    "    :param label_to_see: Label to visualize in explanation\n",
    "    :param dir_path: Path to directory where to save the generated image\n",
    "    :return: Path to saved image\n",
    "    '''\n",
    "\n",
    "    # Plot original image on the left\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(orig_img)\n",
    "\n",
    "    # Plot the image and its explanation on the right\n",
    "    if label_to_see == 'top':\n",
    "        label_to_see = explanation.top_labels[0]\n",
    "    explanation.image = orig_img\n",
    "    temp, mask = explanation.get_image_and_mask(label_to_see, positive_only=False, num_features=10,\n",
    "                                                hide_rest=False)\n",
    "    ax[1].imshow(mark_boundaries(temp, mask))\n",
    "\n",
    "    # Display some information about the example\n",
    "    pred_class = np.argmax(probs)\n",
    "    fig.text(0.02, 0.8, \"Prediction probabilities: \" + str(['{:.2f}'.format(probs[i]) for i in range(len(probs))]),\n",
    "             fontsize=10)\n",
    "    fig.text(0.02, 0.82, \"Predicted Class: \" + str(pred_class) + ' (' + class_names[pred_class] + ')', fontsize=10)\n",
    "    if label is not None:\n",
    "        fig.text(0.02, 0.84, \"Ground Truth Class: \" + str(label) + ' (' + class_names[label] + ')', fontsize=10)\n",
    "    fig.suptitle(\"LIME Explanation for image \" + img_filename, fontsize=13)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Save the image\n",
    "    filename = None\n",
    "    if dir_path is not None:\n",
    "        if not os.path.exists(dir_path):\n",
    "            os.makedirs(dir_path)\n",
    "        filename = dir_path + img_filename.split('/')[-1] + '_exp_' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '.png'\n",
    "        plt.savefig(filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import dill\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "from src.data.preprocess import remove_text\n",
    "from src.visualization.visualize import visualize_explanation\n",
    "\n",
    "\n",
    "def predict_instance(x, model):\n",
    "    '''\n",
    "    Runs model prediction on 1 or more input images.\n",
    "    :param x: Image(s) to predict\n",
    "    :param model: A Keras model\n",
    "    :return: A numpy array comprising a list of class probabilities for each prediction\n",
    "    '''\n",
    "    y = model.predict(x)  # Run prediction on the perturbations\n",
    "    if y.shape[1] == 1:\n",
    "        probs = np.concatenate([1.0 - y, y], axis=1)  # Compute class probabilities from the output of the model\n",
    "    else:\n",
    "        probs = y\n",
    "    return probs\n",
    "\n",
    "\n",
    "def predict_and_explain(x, model, exp, num_features, num_samples):\n",
    "    '''\n",
    "    Use the model to predict a single example and apply LIME to generate an explanation.\n",
    "    :param x: Preprocessed image to predict\n",
    "    :param model: The trained neural network model\n",
    "    :param exp: A LimeImageExplainer object\n",
    "    :param num_features: # of features to use in explanation\n",
    "    :param num_samples: # of times to perturb the example to be explained\n",
    "    :return: The LIME explainer for the instance\n",
    "    '''\n",
    "\n",
    "    def predict(x):\n",
    "        '''\n",
    "        Helper function for LIME explainer. Runs model prediction on perturbations of the example.\n",
    "        :param x: List of perturbed examples from an example\n",
    "        :return: A numpy array constituting a list of class probabilities for each predicted perturbation\n",
    "        '''\n",
    "        probs = predict_instance(x, model)\n",
    "        return probs\n",
    "\n",
    "    # Algorithm for superpixel segmentation. Parameters set to limit size of superpixels and promote border smoothness\n",
    "    segmentation_fn = SegmentationAlgorithm('quickshift', kernel_size=2.25, max_dist=50, ratio=0.1, sigma=0.15)\n",
    "\n",
    "    # Generate explanation for the example\n",
    "    explanation = exp.explain_instance(x, predict, num_features=num_features, num_samples=num_samples, segmentation_fn=segmentation_fn)\n",
    "    probs = predict_instance(np.expand_dims(x, axis=0), model)\n",
    "    return explanation, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def remove_text(img):\n",
    "    '''\n",
    "    Attempts to remove bright textual artifacts from X-ray images. For example, many images indicate the right side of\n",
    "    the body with a white 'R'. Works only for very bright text.\n",
    "    :param img: Numpy array of image\n",
    "    :return: Array of image with (ideally) any characters removed and inpainted\n",
    "    '''\n",
    "    mask = cv2.threshold(img, 230, 255, cv2.THRESH_BINARY)[1][:, :, 0].astype(np.uint8)\n",
    "    img = img.astype(np.uint8)\n",
    "    result = cv2.inpaint(img, mask, 10, cv2.INPAINT_NS).astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_image import *\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import datetime\n",
    "import dill\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#from src.visualization.visualize import visualize_explanation\n",
    "#from src.predict import predict_instance, predict_and_explain\n",
    "#from src.data.preprocess import remove_text\n",
    "\n",
    "\n",
    "def setup_lime():\n",
    "    '''\n",
    "    Load relevant information and create a LIME Explainer\n",
    "    :return: dict containing important information and objects for explanation experiments\n",
    "    '''\n",
    "\n",
    "    # Load relevant constants from project config file\n",
    "    cfg = yaml.full_load(open(os.getcwd() + \"/config.yml\", 'r'))\n",
    "    lime_dict = {}\n",
    "    lime_dict['NUM_SAMPLES'] = cfg['LIME']['NUM_SAMPLES']\n",
    "    lime_dict['NUM_FEATURES'] = cfg['LIME']['NUM_FEATURES']\n",
    "    lime_dict['IMG_PATH'] = cfg['PATHS']['IMAGES']\n",
    "    lime_dict['RAW_DATA_PATH'] = cfg['PATHS']['RAW_DATA']\n",
    "    lime_dict['IMG_DIM'] = cfg['DATA']['IMG_DIM']\n",
    "    lime_dict['PRED_THRESHOLD'] = cfg['PREDICTION']['THRESHOLD']\n",
    "    lime_dict['CLASSES'] = cfg['DATA']['CLASSES']\n",
    "    lime_dict['CLASS_MODE'] = cfg['TRAIN']['CLASS_MODE']\n",
    "    lime_dict['COVID_ONLY'] = cfg['LIME']['COVID_ONLY']\n",
    "    KERNEL_WIDTH = cfg['LIME']['KERNEL_WIDTH']\n",
    "    FEATURE_SELECTION = cfg['LIME']['FEATURE_SELECTION']\n",
    "\n",
    "    # Load train and test sets\n",
    "    lime_dict['TRAIN_SET'] = pd.read_csv(cfg['PATHS']['TRAIN_SET'])\n",
    "    lime_dict['TEST_SET'] = pd.read_csv(cfg['PATHS']['TEST_SET'])\n",
    "\n",
    "    # Create ImageDataGenerator for test set\n",
    "    test_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    test_generator = test_img_gen.flow_from_dataframe(dataframe=lime_dict['TEST_SET'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col='label_str', target_size=tuple(cfg['DATA']['IMG_DIM']), batch_size=1,\n",
    "        class_mode='categorical', validate_filenames=False, shuffle=False)\n",
    "    lime_dict['TEST_GENERATOR'] = test_generator\n",
    "\n",
    "    # Define the LIME explainer\n",
    "    lime_dict['EXPLAINER'] = LimeImageExplainer(kernel_width=KERNEL_WIDTH, feature_selection=FEATURE_SELECTION,\n",
    "                                                verbose=True)\n",
    "    dill.dump(lime_dict['EXPLAINER'], open(cfg['PATHS']['LIME_EXPLAINER'], 'wb'))    # Serialize the explainer\n",
    "\n",
    "    # Load trained model's weights\n",
    "    lime_dict['MODEL'] = load_model(cfg['PATHS']['MODEL_TO_LOAD'], compile=False)\n",
    "\n",
    "    return lime_dict\n",
    "\n",
    "\n",
    "def explain_xray(lime_dict, idx, save_exp=True):\n",
    "    '''\n",
    "    Make a prediction and provide a LIME explanation\n",
    "    :param lime_dict: dict containing important information and objects for explanation experiments\n",
    "    :param idx: index of image in test set to explain\n",
    "    :param save_exp: Boolean indicating whether to save the explanation visualization\n",
    "    '''\n",
    "\n",
    "    # Get i'th preprocessed image in test set\n",
    "    lime_dict['TEST_GENERATOR'].reset()\n",
    "    for i in range(idx + 1):\n",
    "        x, y = lime_dict['TEST_GENERATOR'].next()\n",
    "    x = np.squeeze(x, axis=0)\n",
    "\n",
    "    # Get the corresponding original image (no preprocessing)\n",
    "    orig_img = cv2.imread(lime_dict['RAW_DATA_PATH'] + lime_dict['TEST_SET']['filename'][idx])\n",
    "    new_dim = tuple(lime_dict['IMG_DIM'])\n",
    "    orig_img = cv2.resize(orig_img, new_dim, interpolation=cv2.INTER_NEAREST)     # Resize image\n",
    "\n",
    "    # Make a prediction for this image and retrieve a LIME explanation for the prediction\n",
    "    start_time = datetime.datetime.now()\n",
    "    explanation, probs = predict_and_explain(x, lime_dict['MODEL'], lime_dict['EXPLAINER'],\n",
    "                                      lime_dict['NUM_FEATURES'], lime_dict['NUM_SAMPLES'])\n",
    "    print(\"Explanation time = \" + str((datetime.datetime.now() - start_time).total_seconds()) + \" seconds\")\n",
    "\n",
    "\n",
    "    # Get image filename and label\n",
    "    img_filename = lime_dict['TEST_SET']['filename'][idx]\n",
    "    label = lime_dict['TEST_SET']['label'][idx]\n",
    "\n",
    "    # Rearrange prediction probability vector to reflect original ordering of classes in project config\n",
    "    probs = [probs[0][lime_dict['CLASSES'].index(c)] for c in lime_dict['TEST_GENERATOR'].class_indices]\n",
    "\n",
    "    # Visualize the LIME explanation and optionally save it to disk\n",
    "    if save_exp:\n",
    "        file_path = lime_dict['IMG_PATH']\n",
    "    else:\n",
    "        file_path = None\n",
    "    if lime_dict['COVID_ONLY'] == True:\n",
    "        label_to_see = lime_dict['TEST_GENERATOR'].class_indices['COVID-19']\n",
    "    else:\n",
    "        label_to_see = 'top'\n",
    "    _ = visualize_explanation(orig_img, explanation, img_filename, label, probs, lime_dict['CLASSES'], label_to_see=label_to_see,\n",
    "                          dir_path=file_path)\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lime_dict = setup_lime()\n",
    "i = 0                                                       # Select i'th image in test set\n",
    "explain_xray(lime_dict, i, save_exp=True)                   # Generate explanation for image"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
